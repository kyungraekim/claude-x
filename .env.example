# LLM Provider Configuration
# Choose either Anthropic, OpenAI, or Ollama

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key (for GPT models or compatible APIs)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Base URL (for local Ollama models)
OLLAMA_BASE_URL=http://localhost:11434

# Default LLM Provider
# Options: "anthropic" | "openai" | "ollama"
DEFAULT_LLM_PROVIDER=anthropic

# Default Model
# Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514, claude-haiku-4-20250514
# OpenAI: gpt-4-turbo, gpt-4, gpt-3.5-turbo
# Ollama: llama3.2, llama3.1, mistral, codellama, etc.
DEFAULT_MODEL=claude-sonnet-4-20250514

# LLM Configuration
MAX_TOKENS=4096
TEMPERATURE=0.7

# Agent Configuration
MAX_ITERATIONS=50

# Directory Configuration
# Workspace directory for scratch work
WORKSPACE_DIR=~/.claude-code-ts/workspace

# Skills directory for environment-specific guides
SKILLS_DIR=~/.claude-code-ts/skills

# Outputs directory for final deliverables
OUTPUTS_DIR=~/.claude-code-ts/outputs

# Logging
LOG_LEVEL=info
# Options: debug | info | warn | error
